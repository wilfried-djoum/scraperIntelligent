# ScraperIntelligent

API de profiling professionnel intelligent combinant web scraping et analyse LLM.

## ğŸ“‹ Architecture RefactorisÃ©e

### Structure du Projet

```
ScraperIntelligent/
â”œâ”€â”€ main.py                          # Point d'entrÃ©e FastAPI (60 lignes)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                    # Configuration centralisÃ©e
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ profile.py               # ModÃ¨les Pydantic
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ base_scraper.py          # Classe de base pour scrapers
â”‚   â”‚   â”œâ”€â”€ profile_orchestrator.py  # Orchestration du workflow
â”‚   â”‚   â”œâ”€â”€ llm_analyzer.py          # Service LLM OpenAI
â”‚   â”‚   â”œâ”€â”€ scoring.py               # Calcul du score de fiabilitÃ©
â”‚   â”‚   â””â”€â”€ sources/
â”‚   â”‚       â”œâ”€â”€ linkedin.py          # Scraper LinkedIn
â”‚   â”‚       â”œâ”€â”€ company.py           # Scraper sites entreprise
â”‚   â”‚       â”œâ”€â”€ news.py              # Scraper presse
â”‚   â”‚       â””â”€â”€ social.py            # Scraper rÃ©seaux sociaux
â”‚   â””â”€â”€ static/
â”‚       â”œâ”€â”€ index.html
â”‚       â”œâ”€â”€ main.js
â”‚       â””â”€â”€ styles.css
```

## ğŸ—ï¸ AmÃ©liorations du Refactoring

### 1. Configuration CentralisÃ©e (`src/config.py`)
- âœ… Toutes les clÃ©s API dans un seul endroit
- âœ… Variables d'environnement avec valeurs par dÃ©faut
- âœ… Configuration Firecrawl (version, timeout, wait_for)
- âœ… Configuration OpenAI (model, temperature, max_tokens)
- âœ… ParamÃ¨tres de scraping (retries, max posts, etc.)

### 2. Classe de Base `BaseScraper` (`src/services/base_scraper.py`)
- âœ… Factorisation de l'initialisation Firecrawl
- âœ… Gestion SSL/CA bundle centralisÃ©e
- âœ… MÃ©thodes helper pour extraction sÃ»re (markdown, html, metadata)
- âœ… MÃ©thode `_scrape_url()` gÃ©nÃ©rique
- âœ… Logs cohÃ©rents

### 3. Orchestrateur `ProfileOrchestrator` (`src/services/profile_orchestrator.py`)
- âœ… Extraction de toute la logique mÃ©tier hors de main.py
- âœ… Workflow dÃ©coupÃ© en mÃ©thodes privÃ©es claires:
  - `_scrape_all_sources()` - Lance les scrapers
  - `_extract_profile_data()` - Extrait et structure les donnÃ©es
  - `_calculate_reliability()` - Calcule le score
  - `_assemble_profile()` - Assemble le profil final
- âœ… SÃ©paration des prÃ©occupations (scraping / extraction / enrichissement / scoring)
- âœ… TestabilitÃ© amÃ©liorÃ©e

### 4. Main.py SimplifiÃ©
- âœ… RÃ©duit de ~340 lignes Ã  60 lignes (-82%)
- âœ… ResponsabilitÃ© unique: routing FastAPI
- âœ… DÃ©lÃ©gation complÃ¨te Ã  l'orchestrateur
- âœ… Documentation API amÃ©liorÃ©e

## ğŸš€ Installation

```bash
# Cloner le repo
cd ScraperIntelligent

# Installer les dÃ©pendances
pip install -r requirements.txt

# Configurer les variables d'environnement (optionnel)
cp .env.example .env
# Ã‰diter .env avec vos clÃ©s API
```

## âš™ï¸ Configuration

### Variables d'Environnement

CrÃ©er un fichier `.env` Ã  la racine:

```env
# API Keys
FIRECRAWL_API_KEY=your_firecrawl_key
OPENAI_API_KEY=your_openai_key

# Firecrawl Settings
FIRECRAWL_TIMEOUT=30
FIRECRAWL_WAIT_FOR=3000

# OpenAI Settings
OPENAI_MODEL=gpt-4o-mini
```

Les clÃ©s sont Ã©galement hardcodÃ©es dans `src/config.py` pour le dÃ©veloppement (Ã  retirer en production).

## ğŸƒâ€â™‚ï¸ Lancement

```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

API accessible sur:
- Interface Web: http://localhost:8000/static/index.html
- API Docs: http://localhost:8000/docs
- Endpoint profiling: POST http://localhost:8000/profiling/

## ğŸ“¡ Usage de l'API

### Endpoint `/profiling/`

**Request:**
```json
POST /profiling/
{
    "first_name": "Satya",
    "last_name": "Nadella",
    "company": "Microsoft"
}
```

**Response:**
```json
{
    "debug": {
        "sources_used": ["linkedin", "company", "news", "social"],
        "processing_time": "34.2s"
    },
    "profile": {
        "first_name": "Satya",
        "last_name": "Nadella",
        "company": "Microsoft",
        "headline": "CEO at Microsoft",
        "summary": "...",
        "current_role": "Chief Executive Officer",
        "experiences": [...],
        "skills": [...],
        "education": [...],
        "publications": [...],
        "linkedin_analysis": {...},
        "contact_info": {...},
        "reliability": {
            "score": 85,
            "justification": "...",
            "factors": [...]
        },
        "reputation": {...},
        "sources_used": [...]
    }
}
```

## ğŸ”§ Points Techniques Importants

### Firecrawl v2
Tous les scrapers utilisent maintenant Firecrawl v2:
```python
self.firecrawl = FirecrawlApp(api_key=config.FIRECRAWL_API_KEY, version="v2")
result = self.firecrawl.scrape_url(url, formats=["markdown"], onlyMainContent=True)
markdown = getattr(result, 'markdown', '')  # AccÃ¨s via attributs, pas dict
```

### OpenAI LLM
- ModÃ¨le: **gpt-4o-mini** (coupure octobre 2023)
- Utilisations:
  1. `clean_and_structure()` - Extraction structurÃ©e du contenu scrapÃ©
  2. `summarize_posts()` - Analyse des posts LinkedIn
  3. `global_synthesis()` - SynthÃ¨se narrative du profil
  4. `justify_reliability()` - Justification du score
  5. `enrich_from_knowledge()` - **Fallback** si scraping Ã©choue (donnÃ©es 2023 uniquement)

### Score de FiabilitÃ©
- Base 0-100
- **Sources** (max 40 pts): +10 par source (LinkedIn/Company/News/Social)
- **ComplÃ©tude** (max 60 pts): headline(8), summary(10), experiences(12), publications(8), posts(8), education(6), skills(4), social(4)
- PÃ©nalitÃ© si donnÃ©es LLM avec faible confiance

## âš ï¸ Limitations Connues

1. **LinkedIn** - 403 Forbidden pour la plupart des profils (Anti-scraping)
2. **LLM Knowledge** - DonnÃ©es jusqu'Ã  octobre 2023 seulement
3. **Scraping** - DÃ©pend de la structure HTML des sites (peut casser)
4. **Rate Limiting** - Firecrawl a des limites API

## ğŸ§ª Tests

```bash
# Lancer un test avec une personnalitÃ© publique connue
curl -X POST http://localhost:8000/profiling/ \
  -H "Content-Type: application/json" \
  -d '{"first_name": "Satya", "last_name": "Nadella", "company": "Microsoft"}'
```

## ğŸ“š Prochaines AmÃ©liorations

- [ ] Tests unitaires pour chaque service
- [ ] Cache Redis pour Ã©viter de re-scraper
- [ ] Rate limiting par IP
- [ ] Retry automatique avec backoff exponentiel
- [ ] Logging structurÃ© (JSON logs)
- [ ] Monitoring (Prometheus/Grafana)
- [ ] Migration des clÃ©s API en prod vers variables d'env uniquement
- [ ] Support de recherche web temps rÃ©el (Tavily/Perplexity API)
- [ ] AmÃ©lioration du parsing HTML avec sÃ©lecteurs CSS

## ğŸ“„ License

MIT
